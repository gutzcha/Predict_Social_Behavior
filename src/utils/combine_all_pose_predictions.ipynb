{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d826257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c04a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_mapping_path = osp.join(\"..\",\"assets\",\"file_to_session_mapping_20230930-123448.xlsx\")\n",
    "df_map = pd.read_excel(file_mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f0ce20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_map.loc[~df_map[\"video_pose_estimation\"].isnull(),['rat_number', 'day_number', 'probe_number',\n",
    "       'cropped_raw_video', 'video_pose_estimation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a076322",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['rat_number', 'day_number', 'probe_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce2caf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.iloc[1,:]\n",
    "df_loaded = pd.read_csv(df_sample.video_pose_estimation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a8ee06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ear_left_1_x',\n",
       " 'Ear_left_1_y',\n",
       " 'Ear_right_1_x',\n",
       " 'Ear_right_1_y',\n",
       " 'Nose_1_x',\n",
       " 'Nose_1_y',\n",
       " 'Center_1_x',\n",
       " 'Center_1_y',\n",
       " 'Lat_left_1_x',\n",
       " 'Lat_left_1_y',\n",
       " 'Lat_right_1_x',\n",
       " 'Lat_right_1_y',\n",
       " 'Tail_base_1_x',\n",
       " 'Tail_base_1_y',\n",
       " 'Tail_end_1_x',\n",
       " 'Tail_end_1_y',\n",
       " 'Ear_left_2_x',\n",
       " 'Ear_left_2_y',\n",
       " 'Ear_right_2_x',\n",
       " 'Ear_right_2_y',\n",
       " 'Nose_2_x',\n",
       " 'Nose_2_y',\n",
       " 'Center_2_x',\n",
       " 'Center_2_y',\n",
       " 'Lat_left_2_x',\n",
       " 'Lat_left_2_y',\n",
       " 'Lat_right_2_x',\n",
       " 'Lat_right_2_y',\n",
       " 'Tail_base_2_x',\n",
       " 'Tail_base_2_y',\n",
       " 'Tail_end_2_x',\n",
       " 'Tail_end_2_y',\n",
       " 'Ear_left_1_p',\n",
       " 'Ear_right_1_p',\n",
       " 'Nose_1_p',\n",
       " 'Center_1_p',\n",
       " 'Lat_left_1_p',\n",
       " 'Lat_right_1_p',\n",
       " 'Tail_base_1_p',\n",
       " 'Tail_end_1_p',\n",
       " 'Ear_left_2_p',\n",
       " 'Ear_right_2_p',\n",
       " 'Nose_2_p',\n",
       " 'Center_2_p',\n",
       " 'Lat_left_2_p',\n",
       " 'Lat_right_2_p',\n",
       " 'Tail_base_2_p',\n",
       " 'Tail_end_2_p']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_cols = [a for a in df_loaded.columns if '_x' in a or '_y' in a]\n",
    "prob_cols = [a.replace('_x','_p') for a in joint_cols if '_x' in a]\n",
    "cols = joint_cols + prob_cols\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bc99a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df_list = []\n",
    "# for index, row in df.iterrows():\n",
    "#     df_loaded = pd.read_csv(row.video_pose_estimation)\n",
    "#     df_loaded = df_loaded[cols]\n",
    "#     for par in label_cols:\n",
    "#         df_loaded[par] = row[par]\n",
    "#         all_df_list.append(df_loaded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ded8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df_list = [a.reset_index() for a in all_df_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b0eeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "894f21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df = pd.concat(all_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd819c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df.rename(columns={\"index\":\"frame\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce40f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df.set_index(label_cols, inplace=True)\n",
    "# all_df = pd.read_csv(\"combined_pose_estimation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "506e7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df.to_csv(\"combined_pose_estimation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4606a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_inds = all_df.index.unique()\n",
    "one_rec = all_df.loc[unique_inds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be4401bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ear_left_1_x     431.532736\n",
       "Ear_left_1_y     124.633394\n",
       "Ear_right_1_x    431.133034\n",
       "Ear_right_1_y     80.178687\n",
       "Nose_1_x         403.816611\n",
       "Nose_1_y         107.888238\n",
       "Center_1_x       444.671415\n",
       "Center_1_y       101.585715\n",
       "Lat_left_1_x     494.763195\n",
       "Lat_left_1_y      78.676210\n",
       "Lat_right_1_x    481.424115\n",
       "Lat_right_1_y     76.905941\n",
       "Tail_base_1_x    494.457150\n",
       "Tail_base_1_y    134.171430\n",
       "Tail_end_1_x     502.817444\n",
       "Tail_end_1_y      93.740761\n",
       "Ear_left_2_x     148.546154\n",
       "Ear_left_2_y     111.150253\n",
       "Ear_right_2_x    184.984047\n",
       "Ear_right_2_y    113.048882\n",
       "Nose_2_x         176.792152\n",
       "Nose_2_y          77.346106\n",
       "Center_2_x       167.900000\n",
       "Center_2_y       125.728570\n",
       "Lat_left_2_x     231.344913\n",
       "Lat_left_2_y     207.364955\n",
       "Lat_right_2_x    224.762748\n",
       "Lat_right_2_y    214.347996\n",
       "Tail_base_2_x    174.585710\n",
       "Tail_base_2_y    236.600000\n",
       "Tail_end_2_x     196.610829\n",
       "Tail_end_2_y     225.063948\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_rec[joint_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbccd98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 1/30\n",
    "n_frames_per_sec = 1/fps\n",
    "n_sec_per_seg = 2\n",
    "n_frames_per_seg = np.floor(n_sec_per_seg * n_frames_per_sec)\n",
    "n_frames_per_seg\n",
    "overlap_percent = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames_per_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272bb026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "def sliding_cwt(data, num_frames_per_segment, overlap_percent):\n",
    "    if overlap_percent < 0 or overlap_percent >= 1:\n",
    "        raise ValueError(\"Overlap percent must be between 0 and 1\")\n",
    "        \n",
    "    bandwidth_frequency = 1.5\n",
    "    center_frequency = 1\n",
    "    cmor = f'cmor{bandwidth_frequency}-{center_frequency}'\n",
    "    \n",
    "    step_size = int(np.ceil(num_frames_per_segment * overlap_percent))\n",
    "    num_steps = int(np.ceil((len(data) - num_frames_per_segment) / step_size)) + 1\n",
    "    num_frames_per_segment = int(num_frames_per_segment)\n",
    "\n",
    "    \n",
    "    cwt_matrix = np.empty((num_steps, *pywt.cwt(data[:num_frames_per_segment], [1], cmor, num_frames_per_segment).shape))\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        start_idx = i * step_size\n",
    "        end_idx = start_idx + num_frames_per_segment\n",
    "        segment = data[start_idx:end_idx]\n",
    "        cwt = pywt.cwt(segment, [1], cmor, num_frames_per_segment)\n",
    "        cwt_matrix[i] = cwt\n",
    "\n",
    "    return cwt_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762bcb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = one_rec[joint_cols[0]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "from utils.helper_functions import continuous_wavelet_transform\n",
    "os.chdir(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcdc66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth_frequency = 1.5\n",
    "center_frequency = 1\n",
    "cmor = f'cmor{bandwidth_frequency}-{center_frequency}'\n",
    "num_frames_per_segment = n_frames_per_seg\n",
    "\n",
    "step_size = int(np.ceil(num_frames_per_segment * overlap_percent))\n",
    "num_steps = int(np.ceil((len(data) - num_frames_per_segment) / step_size)) + 1\n",
    "num_frames_per_segment = int(num_frames_per_segment)\n",
    " \n",
    "    \n",
    "f_min = 1  # Minimum frequency\n",
    "f_max = 30  # Maximum frequency\n",
    "\n",
    "# Define the number of frequencies you want (e.g., 10)\n",
    "num_frequencies = 10\n",
    "\n",
    "# Calculate the scales for the desired frequencies\n",
    "# scales = [1 / (2 * np.pi * freq) for freq in np.linspace(f_min, f_max, num_frequencies)]\n",
    "\n",
    "scales = np.linspace(f_min, f_max, num_frequencies)\n",
    "    \n",
    "cwt_result, freqs = pywt.cwt(data[:num_frames_per_segment], scales, cmor, sampling_period=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3aaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4536c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b25995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 1\n",
    "fn = 10\n",
    "num_frequencies = 50\n",
    "fs = 30\n",
    "wavelet = 'morl'\n",
    "num_frames_per_segment = int(fs*30000)\n",
    "frequencies = np.linspace(f0, fn, num_frequencies)\n",
    "scale = pywt.frequency2scale(cmor, frequencies)\n",
    "cwt_result, freqs = pywt.cwt(data, scale, wavelet)\n",
    "\n",
    "t = np.arange(0, cwt_result.shape[1]) / fs\n",
    "# cwt_result = np.abs(cwt_result)\n",
    "cwt_result /= np.abs(cwt_result).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf0b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_0 = 20\n",
    "step_size = 10\n",
    "\n",
    "plot_ind = range(int(fs*t_0), int(fs*(t_0+step_size)))\n",
    "plt.pcolormesh(t[plot_ind], frequencies ,cwt_result[:,plot_ind], shading='gouraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a99eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(t_0, data.shape[0]/fs-plot_range, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa2f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Assuming you have already defined t, frequencies, fs, and cwt_result\n",
    "fs = 29\n",
    "t_0 = 0\n",
    "plot_range = 20\n",
    "plot_ind = range(int(fs * t_0), int(fs * (t_0 + plot_range)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "pcm = ax.pcolormesh(t[plot_ind], frequencies, cwt_result[:, plot_ind], shading='gouraud')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Frequencies')\n",
    "ax.set_title(f't_0 = {t_0}')\n",
    "\n",
    "def update(t_0):\n",
    "    plot_ind = range(int(fs * t_0), int(fs * (t_0 + plot_range)))\n",
    "    pcm.set_array(cwt_result[:, plot_ind])\n",
    "    ax.set_title(f't_0 = {t_0}')\n",
    "    return pcm,\n",
    "\n",
    "# Define the range of t_0 values for the animation\n",
    "t_0_values = np.linspace(t_0, data.shape[0]/fs-plot_range, 100)\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=t_0_values, blit=True)\n",
    "# ani.save('cwt_animation.gif', writer='pillow')  # You can save the animation as a GIF\n",
    "\n",
    "# In Jupyter Notebook, you can display the animation using:\n",
    "from IPython.display import HTML\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "time, frequencies, cwt_matrix = continuous_wavelet_transform(\n",
    "    data[:num_frames_per_segment], fs=30, f0=1e-5, fn=10, num_frequencies=10, wavelet='morl')\n",
    "cwt_matrix = np.abs(cwt_matrix)\n",
    "plt.pcolormesh(time, frequencies, cwt_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwt_out = np.abs(cwt_result)\n",
    "plt.pcolormesh(cwt_out, shading='gouraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e3548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detemine the length of the videos\n",
    "from moviepy.editor import VideoFileClip\n",
    "all_durations = 0\n",
    "video_paths = df['cropped_raw_video'].values\n",
    "with VideoFileClip(video_path) as video:\n",
    "    duration = video.duration\n",
    "    all_durations += duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4eadcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moviepy'"
     ]
    }
   ],
   "source": [
    "import moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4703d797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Predict_Social_Behavior)",
   "language": "python",
   "name": "pycharm-28b9a5e7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
